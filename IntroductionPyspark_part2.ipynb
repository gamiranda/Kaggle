{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2669146,"sourceType":"datasetVersion","datasetId":55151}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check out the part1: https://www.kaggle.com/code/gamirandads/introduction-to-pyspark-part1","metadata":{}},{"cell_type":"markdown","source":"#### If the notebook was usefull in any way, please vote up!","metadata":{}},{"cell_type":"markdown","source":"### Function in the notebook\n\nIn this notebook we will work with some types of **join** available in PySpark.","metadata":{}},{"cell_type":"code","source":"pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:57:38.808232Z","iopub.execute_input":"2024-04-29T18:57:38.808832Z","iopub.status.idle":"2024-04-29T18:58:47.411632Z","shell.execute_reply.started":"2024-04-29T18:57:38.808787Z","shell.execute_reply":"2024-04-29T18:58:47.410463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:58:59.821811Z","iopub.execute_input":"2024-04-29T18:58:59.822327Z","iopub.status.idle":"2024-04-29T18:58:59.948033Z","shell.execute_reply.started":"2024-04-29T18:58:59.822251Z","shell.execute_reply":"2024-04-29T18:58:59.946229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark = (\n    SparkSession.builder\n    .master('local')\n    .appName('PySpark_Introdution_part2')\n    .getOrCreate() #If there were another prev session, It would start it again\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:59:02.264897Z","iopub.execute_input":"2024-04-29T18:59:02.266322Z","iopub.status.idle":"2024-04-29T18:59:09.382027Z","shell.execute_reply.started":"2024-04-29T18:59:02.266245Z","shell.execute_reply":"2024-04-29T18:59:09.380862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customers_d = spark.read.csv('/kaggle/input/brazilian-ecommerce/olist_customers_dataset.csv',\n                                   header=True, \n                                   inferSchema=True, #Will infer the variable types\n                                   sep = \",\")\n\norders_d = spark.read.csv('/kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv',\n                                   header=True, \n                                   inferSchema=True, #Will infer the variable types\n                                   sep = \",\")\n\nreviews_d = spark.read.csv('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv',\n                                   header=True, \n                                   inferSchema=True, #Will infer the variable types\n                                   sep = \",\")\n\npayments_d = spark.read.csv('/kaggle/input/brazilian-ecommerce/olist_order_payments_dataset.csv',\n                                   header=True, \n                                   inferSchema=True, #Will infer the variable types\n                                   sep = \",\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:07:14.652366Z","iopub.execute_input":"2024-04-29T20:07:14.652758Z","iopub.status.idle":"2024-04-29T20:07:17.241195Z","shell.execute_reply.started":"2024-04-29T20:07:14.652732Z","shell.execute_reply":"2024-04-29T20:07:17.239960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customers_d.show(5)\n\nprint((customers_d.count(), len(customers_d.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T19:34:35.157982Z","iopub.execute_input":"2024-04-29T19:34:35.158426Z","iopub.status.idle":"2024-04-29T19:34:35.651334Z","shell.execute_reply.started":"2024-04-29T19:34:35.158393Z","shell.execute_reply":"2024-04-29T19:34:35.650067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orders_d.show(5)\n\nprint((orders_d.count(), len(orders_d.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T19:34:50.206418Z","iopub.execute_input":"2024-04-29T19:34:50.206932Z","iopub.status.idle":"2024-04-29T19:34:50.660233Z","shell.execute_reply.started":"2024-04-29T19:34:50.206894Z","shell.execute_reply":"2024-04-29T19:34:50.658829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews_d.show(5)\n\nprint((reviews_d.count(), len(reviews_d.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T19:35:42.046616Z","iopub.execute_input":"2024-04-29T19:35:42.048098Z","iopub.status.idle":"2024-04-29T19:35:42.441337Z","shell.execute_reply.started":"2024-04-29T19:35:42.048043Z","shell.execute_reply":"2024-04-29T19:35:42.440143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"payments_d.show(5)\n\nprint((payments_d.count(), len(payments_d.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:07:21.003933Z","iopub.execute_input":"2024-04-29T20:07:21.004368Z","iopub.status.idle":"2024-04-29T20:07:21.383569Z","shell.execute_reply.started":"2024-04-29T20:07:21.004337Z","shell.execute_reply":"2024-04-29T20:07:21.382380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can notice that customers_d and orders_d have a commom variable, customer_id, as orders_d and reviews_d has order_id. We can connect both datasets through the join function. PySpark has a few options of join available:\n\n- Inner Join: Returns only the rows with matching keys in both DataFrames.\n- Left Join: Returns all rows from the left DataFrame and matching rows from the right DataFrame.\n- Right Join: Returns all rows from the right DataFrame and matching rows from the left DataFrame.\n- Full Outer Join: Returns all rows from both DataFrames, including matching and non-matching rows.\n- Left Anti Join: Returns all rows from the left DataFrame where there is no match in the right DataFrame.\n- Left Semi Join: Returns all rows from the left DataFrame where there is a match in the right DataFrame.","metadata":{}},{"cell_type":"markdown","source":"### Inner join","metadata":{}},{"cell_type":"markdown","source":"For this example we want in the same dataset the orderes and their reviews.","metadata":{}},{"cell_type":"code","source":"inner_example = orders_d.join(reviews_d, on = 'order_id', how = 'inner')\n\ninner_example.show(n = 3, vertical=True)\n\nprint((inner_example.count(), len(inner_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:15:58.588682Z","iopub.execute_input":"2024-04-29T20:15:58.589193Z","iopub.status.idle":"2024-04-29T20:16:02.008568Z","shell.execute_reply.started":"2024-04-29T20:15:58.589137Z","shell.execute_reply":"2024-04-29T20:16:02.007381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can notice that in the inner_example we have less observations than orders_d. Maybe some orders don't have reviews yet, so in the inner_example we \"selected\" only orders with reviews.","metadata":{}},{"cell_type":"markdown","source":"### Left join","metadata":{}},{"cell_type":"markdown","source":"In this example we want in the same dataset the customer \"main\" info and their orders.","metadata":{}},{"cell_type":"code","source":"left_example = customers_d.join(orders_d, on = 'customer_id', how = 'left') #or leftouter, left_outer\n\nleft_example.show(n = 3, vertical=True)\n\nprint((left_example.count(), len(left_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:25:12.976607Z","iopub.execute_input":"2024-04-29T20:25:12.977060Z","iopub.status.idle":"2024-04-29T20:25:15.171349Z","shell.execute_reply.started":"2024-04-29T20:25:12.977029Z","shell.execute_reply":"2024-04-29T20:25:15.170069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for coluna in left_example.columns:\n    print(coluna, left_example.filter(left_example[coluna].isNull()).count())","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:25:20.528155Z","iopub.execute_input":"2024-04-29T20:25:20.528557Z","iopub.status.idle":"2024-04-29T20:25:32.468176Z","shell.execute_reply.started":"2024-04-29T20:25:20.528528Z","shell.execute_reply":"2024-04-29T20:25:32.467109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note we have the same number of observations in both customers_d and left_example, as expected since we are using left join.","metadata":{}},{"cell_type":"code","source":"for coluna in orders_d.columns:\n    print(coluna, orders_d.filter(orders_d[coluna].isNull()).count())","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:29:08.988822Z","iopub.execute_input":"2024-04-29T20:29:08.989388Z","iopub.status.idle":"2024-04-29T20:29:12.261151Z","shell.execute_reply.started":"2024-04-29T20:29:08.989345Z","shell.execute_reply":"2024-04-29T20:29:12.259834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also we have the same null seen in orders, in left_example.","metadata":{}},{"cell_type":"markdown","source":"### Right join","metadata":{}},{"cell_type":"code","source":"right_example = customers_d.join(orders_d, on = 'customer_id', how = 'rightouter') #or right, right_outer\n\nright_example.show(n = 3, vertical=True)\n\nprint((right_example.count(), len(right_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:02:49.164564Z","iopub.execute_input":"2024-04-29T20:02:49.164962Z","iopub.status.idle":"2024-04-29T20:02:51.115582Z","shell.execute_reply.started":"2024-04-29T20:02:49.164934Z","shell.execute_reply":"2024-04-29T20:02:51.114390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As costumers_d and orders_d have the same number of observations (the same observations), right and left join returns us the same result.","metadata":{}},{"cell_type":"markdown","source":"### Full join","metadata":{}},{"cell_type":"code","source":"full_example = orders_d.join(reviews_d, on = 'order_id', how = 'full') #or outer, fullouter\n\nfull_example.show(n = 3, vertical=True)\n\nprint((full_example.count(), len(full_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:36:08.420529Z","iopub.execute_input":"2024-04-29T20:36:08.420931Z","iopub.status.idle":"2024-04-29T20:36:11.669076Z","shell.execute_reply.started":"2024-04-29T20:36:08.420902Z","shell.execute_reply":"2024-04-29T20:36:11.668230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Left Anti Join","metadata":{}},{"cell_type":"markdown","source":"Remember when we create inner_example, we had less observations than in orders_d, which could be orders with no review. One way to see those orders is using left anti join","metadata":{}},{"cell_type":"code","source":"left_anti_example = orders_d.join(reviews_d, on = 'order_id', how = 'leftanti') # or anti, left_anti\n\nleft_anti_example.show(n = 3, vertical=True)\n\nprint((left_anti_example.count(), len(left_anti_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:40:09.608512Z","iopub.execute_input":"2024-04-29T20:40:09.609721Z","iopub.status.idle":"2024-04-29T20:40:11.737043Z","shell.execute_reply.started":"2024-04-29T20:40:09.609685Z","shell.execute_reply":"2024-04-29T20:40:11.735852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, there is 768 orders with no review.","metadata":{}},{"cell_type":"markdown","source":"### Left Semi Join","metadata":{}},{"cell_type":"markdown","source":"Left semi join is very similar to inner join. The only difference is that inner join returns the columns from both datasets and left semi join returns only the columns from the left dataset.","metadata":{}},{"cell_type":"code","source":"left_semi_example = orders_d.join(reviews_d, on = 'order_id', how = 'leftsemi') # or semi, left_semi\n\nleft_semi_example.show(n = 3, vertical=True)\n\nprint((left_semi_example.count(), len(left_semi_example.columns)))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:45:37.996559Z","iopub.execute_input":"2024-04-29T20:45:37.997011Z","iopub.status.idle":"2024-04-29T20:45:39.970182Z","shell.execute_reply.started":"2024-04-29T20:45:37.996980Z","shell.execute_reply":"2024-04-29T20:45:39.969365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Source: https://sparkbyexamples.com/pyspark/pyspark-join-explained-with-examples/#pyspark-left-outer-join","metadata":{}}]}